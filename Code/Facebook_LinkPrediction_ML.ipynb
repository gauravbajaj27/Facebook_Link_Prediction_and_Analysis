{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Facebook_LinkPrediction_ML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "from sklearn import svm\n",
        "from operator import itemgetter\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import csv\n",
        "import datetime\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.preprocessing import normalize\n",
        "import multiprocessing as mp\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import linear_model\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from zipfile import ZipFile as zipfile"
      ],
      "metadata": {
        "id": "UoE9Qkdob4iu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # importing required modules\n",
        "# from zipfile import ZipFile\n",
        "\n",
        "# # specifying the zip file name\n",
        "# file_name = \"facebook.zip\"\n",
        "\n",
        "# # opening the zip file in READ mode\n",
        "# with ZipFile(file_name, 'r') as zip:\n",
        "# \t# printing all the contents of the zip file\n",
        "# \tzip.printdir()\n",
        "\n",
        "# \t# extracting all the files\n",
        "# \tprint('Extracting all the files now...')\n",
        "# \tzip.extractall()\n",
        "# \tprint('Done!')"
      ],
      "metadata": {
        "id": "n5lyg4rSwB5a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Complete Dataset Graph"
      ],
      "metadata": {
        "id": "D9fRKBYVxHdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.Graph()"
      ],
      "metadata": {
        "id": "jvY8CaxwBPpM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def buildGraph(G):\n",
        "    fileName=\"/content/facebook_combined/facebook_combined.txt\"\n",
        "    f=open(fileName)\n",
        "    line=f.readline()\n",
        "    while(line!=''):\n",
        "      c=(line.split())\n",
        "      G.add_edge(int(c[0]), int(c[1]))\n",
        "      line=f.readline()\n",
        "    f.close()\n",
        "buildGraph(G)"
      ],
      "metadata": {
        "id": "44Okzl33rnzo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CommonNeighbors(u, v, g):\n",
        "    u_n = set(g.neighbors(u))\n",
        "    v_n = set(g.neighbors(v))\n",
        "    return len(u_n.intersection(v_n))\n",
        "def common_neighbors(g, edges):\n",
        "    res = []\n",
        "    for edge in edges:\n",
        "        node1, node2 = edge[0], edge[1]\n",
        "        num_common_neighbors = 0\n",
        "        try:\n",
        "            n_1, n_2 = g.neighbors(node1), g.neighbors(node2)\n",
        "            for neighbor in n_1:\n",
        "                if neighbor in n_2:\n",
        "                    num_common_neighbors += 1\n",
        "            res.append((node1, node2, num_common_neighbors))\n",
        "        except:\n",
        "            pass\n",
        "    return res"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-27T21:31:45.787596Z",
          "iopub.execute_input": "2022-04-27T21:31:45.788019Z",
          "iopub.status.idle": "2022-04-27T21:31:50.023386Z",
          "shell.execute_reply.started": "2022-04-27T21:31:45.787988Z",
          "shell.execute_reply": "2022-04-27T21:31:50.022452Z"
        },
        "trusted": true,
        "id": "_VzfEAVVb4it"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featuresSet = [common_neighbors,\n",
        "                   nx.resource_allocation_index,\n",
        "                   nx.jaccard_coefficient,\n",
        "                   nx.adamic_adar_index,\n",
        "                   nx.preferential_attachment\n",
        "                   ]"
      ],
      "metadata": {
        "id": "N4MWo7rpBgPn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ProduceFakeEdge(g, negative_graph,NumTestEdges):\n",
        "    i = 0\n",
        "    while i < NumTestEdges:\n",
        "        edge = random.sample(g.nodes(), 2)\n",
        "        try:\n",
        "            shortestPath = nx.shortest_path_length(g,source=edge[0],target=edge[1])\n",
        "            if shortestPath >= 2:\n",
        "                negative_graph.add_edge(edge[0],edge[1], positive=\"False\")\n",
        "                i += 1\n",
        "        except:\n",
        "            pass"
      ],
      "metadata": {
        "id": "D9j0v4yABiPw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CreateGraphFromFile(f_name):\n",
        "    f = open(f_name, \"rb\")\n",
        "    g = nx.read_edgelist(f)\n",
        "    return g"
      ],
      "metadata": {
        "id": "3aKNl_3GBqUO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SampleExtraction(g, positive_number, negative_number, negative_mode, negative_distance=2, d=1):\n",
        "    \"\"\"\n",
        "\n",
        "    :param g:  the graph\n",
        "    :param positive_number: the number of positive samples\n",
        "    :param negative_number: the number of negative samples\n",
        "    :param negative_distance: the distance between two nodes in negative samples\n",
        "    :param d: if d ==0, don't d positive edges from graph\n",
        "    :return: positive_sample is a list of positive edges, negative_sample is a list of negative edges\n",
        "    \"\"\"\n",
        "\n",
        "    # Randomly selecting positive_number as test edges\n",
        "    \n",
        "    positive_sample = random.sample(g.edges(), positive_number)\n",
        "    sample_graph = nx.Graph()\n",
        "    sample_graph.add_edges_from(positive_sample, positive=\"True\")\n",
        "    nx.write_edgelist(sample_graph, \"sample_positive_\" +str(positive_number)+ \".txt\", data=['positive'])\n",
        "\n",
        "    #   Adding non-existing edges to test\n",
        "\n",
        "    i = 0\n",
        "    negative_graph = nx.Graph()\n",
        "    ProduceFakeEdge(g,negative_graph,negative_number)\n",
        "    nx.write_edgelist(negative_graph, \"sample_negative_\" +str(negative_number)+ \".txt\", data=[\"positive\"])\n",
        "    negative_sample = negative_graph.edges()\n",
        "    negative_graph.add_edges_from(positive_sample,positive=\"True\")\n",
        "    nx.write_edgelist(negative_graph, \"sample_combine_\" +str(positive_number + negative_number)+ \".txt\", data=[\"positive\"])\n",
        "\n",
        "    if d == 0:\n",
        "        return positive_sample, negative_sample\n",
        "    else:\n",
        "        g.remove_edges_from(positive_sample)\n",
        "        nx.write_edgelist(g, \"training.txt\", data=False)\n",
        "\n",
        "        return positive_sample, negative_sample"
      ],
      "metadata": {
        "id": "qfPgDjTPBtQS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def FeatureExtraction(g, positive_sample, negative_sample, feature_name, model=\"single\", combine_num=5):\n",
        "\n",
        "    data = []\n",
        "    if model == \"single\":\n",
        "        preds = feature_name(g, positive_sample)\n",
        "        feature = [feature_name.__name__] + [i[2] for i in preds]\n",
        "        label = [\"label\"] + [\"Pos\" for i in range(len(feature))]\n",
        "        preds = feature_name(g, negative_sample)\n",
        "        feature1 = [i[2] for i in preds]\n",
        "        feature = feature + feature1\n",
        "        label = label + [\"Neg\" for i in range(len(feature1))]\n",
        "        data = [feature, label]\n",
        "        data = trans(data)\n",
        "        WriteData(data, \"features_\" + model + \"_\" + feature_name.__name__ + \".csv\")\n",
        "    else:\n",
        "        label = [\"label\"] + [\"1\" for i in range(len(positive_sample))] + [\"0\" for i in range(len(negative_sample))]\n",
        "        for j in feature_name:\n",
        "            preds = j(g, positive_sample)\n",
        "\n",
        "            feature = [j.__name__] + [i[2] for i in preds]\n",
        "            preds = j(g, negative_sample)\n",
        "            feature = feature + [i[2] for i in preds]\n",
        "            data.append(feature)\n",
        "\n",
        "        data.append(label)\n",
        "        data = trans(data)\n",
        "        WriteData(data, \"features_\" + model + \"_\" + str(combine_num) + \".csv\")\n",
        "    return data\n",
        "\n",
        "\n",
        "def WriteData(data, f_name):\n",
        "    csvfile = open(f_name, \"w\")\n",
        "    writer = csv.writer(csvfile)\n",
        "    for i in data:\n",
        "        writer.writerow(i)\n",
        "    csvfile.close()\n",
        "\n",
        "\n",
        "def trans(data):\n",
        "    return [list(i) for i in zip(*data)]"
      ],
      "metadata": {
        "id": "BVr9OAUpBvH1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(f_name=\"/content/facebook_combined/facebook_combined.txt\", positive_number=0.1, negative_number=0.1, model=\"combined\", combine_num=1,\n",
        "         feature_name=common_neighbors, negative_mode=\"hard\"):\n",
        "    if combine_num==2:\n",
        "        positive_number=0.008;\n",
        "        negative_number=0.008;\n",
        "    g = CreateGraphFromFile(f_name)\n",
        "    num_edges = g.number_of_edges()\n",
        "    positive_number = int(num_edges * positive_number)\n",
        "    negative_number = int(num_edges * negative_number)\n",
        "    positive_sample, negative_sample = SampleExtraction(g, positive_number, negative_number,negative_mode)\n",
        "    train_data = FeatureExtraction(g, positive_sample, negative_sample, feature_name, model, combine_num)"
      ],
      "metadata": {
        "id": "Sq9H6zx6BzqB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fn=\"/content/facebook_combined/facebook_combined.txt\";\n",
        "cn=2;"
      ],
      "metadata": {
        "id": "Q9XDnk9nDzV8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run this line to genrate feature Set\n",
        "main(f_name=fn,model=\"combined\",combine_num=cn, feature_name=featuresSet, negative_mode=\"easy\")"
      ],
      "metadata": {
        "id": "U4kDelEWB2WZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r=np.loadtxt(open(\"features_combined_\"+str(cn)+\".csv\", \"rb\"), delimiter=\",\", skiprows=1);"
      ],
      "metadata": {
        "id": "Tp2DCyrwB28i"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l,b=r.shape;"
      ],
      "metadata": {
        "id": "yXdhegw-B5No"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.shuffle(r);"
      ],
      "metadata": {
        "id": "ANNFY7qdCBLb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_I=int(0.8*l)\n",
        "X_train=r[0:t_I,0:b-1]\n",
        "Y_train=r[0:t_I,b-1]\n",
        "\n",
        "X_test=r[t_I:l,0:b-1]\n",
        "Y_test=r[t_I:l,b-1]\n",
        "\n",
        "X_train = normalize(X_train, axis=0, norm='max')\n",
        "X_test = normalize(X_test, axis=0, norm='max')\n",
        "\n",
        "scaler = StandardScaler()  \n",
        "scaler.fit(X_train)  \n",
        "\n",
        "X_train = scaler.transform(X_train)  \n",
        "X_test = scaler.transform(X_test)  "
      ],
      "metadata": {
        "id": "p_HKsK9lCFf4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SVM_Model(train, t_lables, test, test_labels):\n",
        "    #Support Vector Machine\n",
        "    model_1 = svm.SVC()\n",
        "    model_1.fit(train, t_lables)\n",
        "    result = model_1.predict(test)\n",
        "\n",
        "    print (\"Accuracy of SVM Model:\", accuracy_score(test_labels, result))"
      ],
      "metadata": {
        "id": "b0qSmhkmCGSZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Accuracy of SVM model\n",
        "SVM_Model(X_train,Y_train,X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-sTa9tjCJ_b",
        "outputId": "4c484170-7147-4def-9adf-5e76f806ae42"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of SVM Model: 0.640661938534279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Logistic_Model(train, t_lables, test, test_labels):\n",
        "    model_1 = LogisticRegression(random_state=0, solver='lbfgs',multi_class='ovr').fit(train, t_lables)\n",
        "    model_1.fit(train, t_lables)\n",
        "    result=model_1.predict(test)\n",
        "    print (\"Accuracy of Logistics Regression Model:\", accuracy_score(test_labels, result))"
      ],
      "metadata": {
        "id": "4KNNK-StCLxt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy of Logistic Regression Model\n",
        "Logistic_Model(X_train,Y_train,X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJtznAWtCMkR",
        "outputId": "7d7992e9-a8fb-48a2-dee4-895332345b45"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Logistics Regression Model: 0.6595744680851063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ANN_Model(train, t_lables, test, test_labels):\n",
        "    model_1 = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(15,9), random_state=1)\n",
        "    model_1.fit(train, t_lables)\n",
        "    result = model_1.predict(test)\n",
        "    print (\"ANN Model Accuracy:\", accuracy_score(test_labels, result))\n",
        "    "
      ],
      "metadata": {
        "id": "Pzgc95zmCOjo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy of ANN Model\n",
        "ANN_Model(X_train,Y_train,X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RACHozXCSj9",
        "outputId": "c8afcb5b-7648-45d7-c698-2a5d39049139"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANN Model Accuracy: 0.6572104018912529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    }
  ]
}